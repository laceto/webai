{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-placeholder",
   "metadata": {},
   "source": "# `webai.ticker` — User Guide\n\nOrchestrates multi-query Tavily fan-out + LLM synthesis into validated Pydantic research objects for **individual tickers** and **market sectors**.\n\n```\nwebai/ticker.py\n│\n├── Models\n│   ├── TickerResearch        validated snapshot for one stock\n│   └── SectorResearch        validated snapshot for one sector\n│\n├── TickerResearcher(model, ...)\n│   ├── research_ticker(symbol, company_name=None)  → TickerResearch\n│   └── research_sector(sector)                     → SectorResearch\n│\n└── TRUSTED_DOMAINS           module-level domain allowlist\n```\n\n| Method | Returns | Needs API keys |\n|---|---|---|\n| `research_ticker` | `TickerResearch` | TAVILY_API_KEY + OPENAI_API_KEY |\n| `research_sector` | `SectorResearch` | TAVILY_API_KEY + OPENAI_API_KEY |\n\n**Prerequisites:**\n- Sections 1–2 (setup, model schemas) run **without** API keys.\n- Sections 3–7 require both `TAVILY_API_KEY` and `OPENAI_API_KEY` in `.env`.\n\n## Sections\n1. [Setup](#1-setup)\n2. [Output model schemas](#2-output-model-schemas)\n3. [Initialization](#3-initialization)\n4. [research_ticker](#4-research_ticker)\n5. [research_sector](#5-research_sector)\n6. [Customization](#6-customization)\n7. [End-to-end pattern](#7-end-to-end-pattern)\n8. [Error handling reference](#8-error-handling-reference)"
  },
  {
   "cell_type": "markdown",
   "id": "861ed55rwrp",
   "source": "## 1 — Setup <a id=\"1-setup\"></a>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "nm363jk3jg9",
   "source": "import json\nimport logging\nimport os\n\nfrom dotenv import load_dotenv\n\nfrom webai.ticker import TRUSTED_DOMAINS, SectorResearch, TickerResearch, TickerResearcher\n\nload_dotenv()\n\nlogging.basicConfig(\n    level=logging.WARNING,  # flip to DEBUG to see the full pipeline trace\n    format=\"%(asctime)s [%(levelname)s] %(name)s — %(message)s\",\n    force=True,\n)\n\n_HAS_TAVILY = bool(os.environ.get(\"TAVILY_API_KEY\"))\n_HAS_OPENAI = bool(os.environ.get(\"OPENAI_API_KEY\"))\n_HAS_KEYS   = _HAS_TAVILY and _HAS_OPENAI\n\nprint(f\"TAVILY_API_KEY : {'set' if _HAS_TAVILY else 'MISSING'}\")\nprint(f\"OPENAI_API_KEY : {'set' if _HAS_OPENAI else 'MISSING'}\")\nprint(f\"Live sections  : {'enabled' if _HAS_KEYS else 'SKIPPED — set both keys in .env'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7a81rb1zcn3",
   "source": "## 2 — Output model schemas <a id=\"2-output-model-schemas\"></a>\n\nBoth research methods return validated Pydantic models. You can inspect the schema without any API keys.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "nsg23o3agm",
   "source": "### 2a — `TickerResearch`\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| `ticker` | `str` | yes | Uppercase symbol, e.g. `\"NVDA\"` |\n| `company_name` | `str` | yes | Full name inferred by LLM |\n| `sentiment` | `Literal[...]` | yes | `bullish / bearish / neutral / mixed` |\n| `confidence` | `float [0–1]` | yes | Evidence consistency score |\n| `key_catalyst` | `str` | yes | Single most important near-term catalyst |\n| `risk_factors` | `list[str]` | no | 3–5 specific downside risks |\n| `analyst_consensus` | `str` | no | Ratings / price targets if mentioned |\n| `macro_context` | `str` | no | Macro / sector context from step-back queries |\n| `sources` | `list[str]` | no | Source URLs used in synthesis |\n| `freshness_warning` | `bool` | no | `True` if sources appear >30 days old |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "2f2ljym3h1q",
   "source": "# Pretty-print the JSON schema — no API key required\nschema = TickerResearch.model_json_schema()\nprint(json.dumps(schema, indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f8ghci5qum",
   "source": "### 2b — `SectorResearch`\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| `sector` | `str` | yes | Exactly the string the caller passed in |\n| `overall_health` | `Literal[...]` | yes | `strong / weak / stable / deteriorating / mixed` |\n| `key_trends` | `list[str]` | no | 3–5 structural or cyclical trends |\n| `tailwinds` | `list[str]` | no | 2–4 positive near-term drivers |\n| `headwinds` | `list[str]` | no | 2–4 negative pressures / risks |\n| `valuation_note` | `str` | no | P/E / multiples commentary; empty if absent |\n| `leading_companies` | `list[str]` | no | Top 3–5 names mentioned in sources |\n| `macro_sensitivity` | `str` | no | Sensitivity to rates, inflation, credit cycles |\n| `outlook` | `str` | no | 1–2 sentence forward-looking statement |\n| `sources` | `list[str]` | no | Source URLs used in synthesis |\n| `freshness_warning` | `bool` | no | `True` if sources appear >30 days old |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "fuspsxv8gju",
   "source": "schema = SectorResearch.model_json_schema()\nprint(json.dumps(schema, indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ifk0us705zd",
   "source": "## 3 — Initialization <a id=\"3-initialization\"></a>\n\n`TickerResearcher` wraps both research pipelines. Build it once and reuse it for many calls — the two structured-output chains (`_synthesis_chain` and `_sector_synthesis_chain`) are constructed at init time.\n\n### Constructor parameters\n\n| Parameter | Default | Notes |\n|---|---|---|\n| `model` | *(required)* | Any LangChain `BaseChatModel` with `with_structured_output` support |\n| `tavily_api_key` | `$TAVILY_API_KEY` | Falls back to env var |\n| `openai_api_key` | `$OPENAI_API_KEY` | Passed to the underlying `WebSearcher` |\n| `max_results_per_query` | `5` | Tavily results per fan-out query |\n| `trusted_domains` | `TRUSTED_DOMAINS` | Override the allowlist for domain filtering |\n| `filter_by_domain` | `True` | Disable to skip domain filtering entirely |\n| `max_workers` | `8` | Thread pool size for parallel searches |\n| `debug` | `False` | Sets logger to DEBUG + adds StreamHandler |\n\n> **Invariant:** Initialization raises `ValueError` immediately if `TAVILY_API_KEY` is missing. It never silently continues without a valid Tavily key.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4tp3pmdj1le",
   "source": "if not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    from langchain_openai import ChatOpenAI\n\n    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n    researcher = TickerResearcher(\n        model=model,\n        max_results_per_query=3,  # keep calls fast in the guide\n        debug=False,\n    )\n\n    print(f\"filter_by_domain  : {researcher.filter_by_domain}\")\n    print(f\"max_workers       : {researcher.max_workers}\")\n    print(f\"trusted_domains   : {len(researcher.trusted_domains)} entries\")\n    print(f\"First few domains : {researcher.trusted_domains[:5]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pf3kdpzcnv",
   "source": "## 4 — `research_ticker` <a id=\"4-research_ticker\"></a>\n\nRuns the full equity research pipeline for a single stock symbol.\n\n**Pipeline:**\n1. Normalise symbol to uppercase\n2. Build anchor query: `\"{SYMBOL} {company_name} stock analysis news\"`\n3. Fan-out via LLM query translation (expand → decompose → step-back), using finance-domain few-shot examples\n4. Execute all queries in parallel against Tavily `topic=\"finance\"`\n5. Deduplicate by URL; filter to `TRUSTED_DOMAINS` (with unfiltered fallback)\n6. Synthesise a `TickerResearch` via `model.with_structured_output(TickerResearch)`\n\n**When to pass `company_name`:** Always pass it when the ticker is ambiguous or not widely known — it anchors both the Tavily queries and the LLM prompt, improving result relevance.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ob7kdq16jls",
   "source": "if not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    ticker_result = researcher.research_ticker(\"NVDA\", company_name=\"Nvidia\")\n\n    print(f\"ticker            : {ticker_result.ticker}\")\n    print(f\"company_name      : {ticker_result.company_name}\")\n    print(f\"sentiment         : {ticker_result.sentiment}\")\n    print(f\"confidence        : {ticker_result.confidence:.2f}\")\n    print(f\"key_catalyst      : {ticker_result.key_catalyst}\")\n    print(f\"freshness_warning : {ticker_result.freshness_warning}\")\n    print(f\"sources           : {len(ticker_result.sources)} URLs\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e53iqil28sr",
   "source": "# Full JSON export — useful for downstream serialisation or logging\nif not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    print(ticker_result.model_dump_json(indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vtr53q2d35q",
   "source": "# Iterate over list fields for downstream use\nif not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    print(\"Risk factors:\")\n    for i, risk in enumerate(ticker_result.risk_factors, 1):\n        print(f\"  {i}. {risk}\")\n\n    if ticker_result.analyst_consensus:\n        print(f\"\\nAnalyst consensus : {ticker_result.analyst_consensus}\")\n\n    if ticker_result.macro_context:\n        print(f\"\\nMacro context     : {ticker_result.macro_context}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "qyb5hucp4vi",
   "source": "## 5 — `research_sector` <a id=\"5-research_sector\"></a>\n\nRuns the same pipeline as `research_ticker` but targets macro-level sector content instead of individual company news.\n\n**Key differences from `research_ticker`:**\n\n| Aspect | `research_ticker` | `research_sector` |\n|---|---|---|\n| Base query phrase | `\"{SYMBOL} stock analysis news\"` | `\"{sector} sector financial health outlook\"` |\n| Few-shot examples | Finance ticker examples (AAPL, TSLA, MSFT) | Sector examples (Semiconductors, Healthcare, Energy) |\n| Synthesis chain | `TickerResearch` schema | `SectorResearch` schema |\n| Output anchor | `ticker` field locked to symbol | `sector` field locked to caller's string |\n\nThe sector name you pass is stored verbatim in `result.sector`, so you can safely group or key on it downstream.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eezo29tep9e",
   "source": "if not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    sector_result = researcher.research_sector(\"Semiconductors\")\n\n    print(f\"sector            : {sector_result.sector}\")\n    print(f\"overall_health    : {sector_result.overall_health}\")\n    print(f\"freshness_warning : {sector_result.freshness_warning}\")\n    print(f\"sources           : {len(sector_result.sources)} URLs\")\n\n    print(\"\\nKey trends:\")\n    for trend in sector_result.key_trends:\n        print(f\"  • {trend}\")\n\n    print(\"\\nTailwinds:\")\n    for tw in sector_result.tailwinds:\n        print(f\"  + {tw}\")\n\n    print(\"\\nHeadwinds:\")\n    for hw in sector_result.headwinds:\n        print(f\"  - {hw}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d0sof3a5c1",
   "source": "if not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    print(f\"Outlook           : {sector_result.outlook}\")\n\n    if sector_result.valuation_note:\n        print(f\"Valuation note    : {sector_result.valuation_note}\")\n\n    if sector_result.macro_sensitivity:\n        print(f\"Macro sensitivity : {sector_result.macro_sensitivity}\")\n\n    if sector_result.leading_companies:\n        print(f\"Leading companies : {', '.join(sector_result.leading_companies)}\")\n\n    print(\"\\nFull JSON:\")\n    print(sector_result.model_dump_json(indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "njigvc8vh0j",
   "source": "## 6 — Customization <a id=\"6-customization\"></a>\n\n### 6a — Trusted domain allowlist\n\n`TRUSTED_DOMAINS` is a module-level list you can read or extend. Pass `trusted_domains=` to `TickerResearcher` to override it for a specific instance without mutating the module-level constant.\n\n> **Domain filtering invariant:** If every result is excluded by the allowlist, the pipeline automatically falls back to the full unfiltered set rather than raising. You'll see a `WARNING` log line when this happens. Set `filter_by_domain=False` to skip filtering entirely.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "z54sz4j7h5",
   "source": "# Inspect the default allowlist — no API key needed\nprint(f\"Default trusted domains ({len(TRUSTED_DOMAINS)} entries):\")\nfor domain in TRUSTED_DOMAINS:\n    print(f\"  {domain}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6vh89kgxjn",
   "source": "if not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    from langchain_openai import ChatOpenAI\n\n    # Add a custom domain on top of the defaults\n    custom_domains = TRUSTED_DOMAINS + [\"techcrunch.com\", \"arstechnica.com\"]\n\n    researcher_custom = TickerResearcher(\n        model=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n        max_results_per_query=3,\n        trusted_domains=custom_domains,\n    )\n    print(f\"Custom researcher has {len(researcher_custom.trusted_domains)} trusted domains\")\n\n    # Or disable domain filtering entirely (accept any Tavily result)\n    researcher_open = TickerResearcher(\n        model=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n        max_results_per_query=3,\n        filter_by_domain=False,\n    )\n    print(f\"Open researcher   filter_by_domain={researcher_open.filter_by_domain}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "88141idamik",
   "source": "### 6b — Debug logging\n\nPass `debug=True` to route the full pipeline trace to stderr via Python's `logging` module. Each stage logs the number of queries, raw results, deduped results, and domain-filtered results.\n\n```python\nresearcher_debug = TickerResearcher(model=model, debug=True)\n# Now all webai.ticker DEBUG lines stream to stderr\nresult = researcher_debug.research_ticker(\"AAPL\", company_name=\"Apple\")\n```\n\nTo suppress debug output in production, pass `debug=False` (the default) and configure your application's root logger instead.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "fov8ptwfwpq",
   "source": "## 7 — End-to-end pattern <a id=\"7-end-to-end-pattern\"></a>\n\nA common use-case: given a list of tickers, produce both a per-stock snapshot **and** the health of its parent sector, then combine them into a single report dict. The helper below runs all calls through the shared `TickerResearcher` instance so the LLM chains are built only once.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "rykwwx3861l",
   "source": "def research_portfolio(\n    researcher: TickerResearcher,\n    holdings: list[dict],  # [{\"symbol\": str, \"company\": str, \"sector\": str}]\n) -> dict:\n    \"\"\"\n    For each holding, fetch a TickerResearch snapshot and its sector's\n    SectorResearch snapshot (deduplicating sector calls).\n\n    Returns a dict keyed by symbol with nested ticker and sector results.\n    \"\"\"\n    sector_cache: dict[str, SectorResearch] = {}\n    report: dict[str, dict] = {}\n\n    for h in holdings:\n        symbol  = h[\"symbol\"]\n        company = h.get(\"company\")\n        sector  = h[\"sector\"]\n\n        # --- ticker ---\n        ticker_res = researcher.research_ticker(symbol, company_name=company)\n\n        # --- sector (cached so we only call Tavily once per unique sector) ---\n        if sector not in sector_cache:\n            sector_cache[sector] = researcher.research_sector(sector)\n        sector_res = sector_cache[sector]\n\n        report[symbol] = {\n            \"ticker\": ticker_res,\n            \"sector\": sector_res,\n        }\n\n    return report\n\n\n# --- run the helper ---\nif not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    HOLDINGS = [\n        {\"symbol\": \"NVDA\", \"company\": \"Nvidia\",    \"sector\": \"Semiconductors\"},\n        {\"symbol\": \"INTC\", \"company\": \"Intel\",     \"sector\": \"Semiconductors\"},\n        {\"symbol\": \"JNJ\",  \"company\": \"Johnson & Johnson\", \"sector\": \"Healthcare\"},\n    ]\n\n    portfolio = research_portfolio(researcher, HOLDINGS)\n\n    for symbol, data in portfolio.items():\n        t = data[\"ticker\"]\n        s = data[\"sector\"]\n        print(f\"\\n{'='*60}\")\n        print(f\"  {symbol} — {t.company_name}\")\n        print(f\"  Sentiment      : {t.sentiment}  (confidence {t.confidence:.2f})\")\n        print(f\"  Key catalyst   : {t.key_catalyst}\")\n        print(f\"  Sector         : {s.sector}  [{s.overall_health}]\")\n        print(f\"  Sector outlook : {s.outlook[:120]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8ymf1x1vj8u",
   "source": "## 8 — Error handling reference <a id=\"8-error-handling-reference\"></a>\n\n| Method | Guard condition | Exception raised |\n|---|---|---|\n| `TickerResearcher.__init__` | `TAVILY_API_KEY` missing | `ValueError` |\n| `research_ticker` | `symbol` is empty string | `ValueError` |\n| `research_ticker` | no results survive pipeline | `RuntimeError` |\n| `research_ticker` | LLM synthesis fails | `RuntimeError` |\n| `research_sector` | `sector` is empty string | `ValueError` |\n| `research_sector` | no results survive pipeline | `RuntimeError` |\n| `research_sector` | LLM synthesis fails | `RuntimeError` |\n\n> **Fallback behaviour (not an error):** If domain filtering removes every result, the pipeline silently falls back to the full unfiltered set and logs a `WARNING`. You only get `RuntimeError` if *zero* results came back from Tavily in the first place.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "c4z611wprof",
   "source": "# ValueError: empty symbol — no API key needed\nif not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    try:\n        researcher.research_ticker(\"   \")  # whitespace-only\n    except ValueError as e:\n        print(f\"research_ticker('   ') -> ValueError: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ulgo30c5b0o",
   "source": "# ValueError: empty sector — no API key needed\nif not _HAS_KEYS:\n    print(\"Skipping — requires TAVILY_API_KEY and OPENAI_API_KEY.\")\nelse:\n    try:\n        researcher.research_sector(\"\")\n    except ValueError as e:\n        print(f\"research_sector('')    -> ValueError: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2sq4sfwr9sc",
   "source": "# ValueError: missing Tavily key at construction time\n# (This cell always runs — no live API needed)\nimport os as _os\n\n_saved = _os.environ.pop(\"TAVILY_API_KEY\", None)\ntry:\n    from langchain_openai import ChatOpenAI as _ChatOpenAI\n    _m = _ChatOpenAI(model=\"gpt-4o-mini\")\n    TickerResearcher(model=_m)\nexcept ValueError as e:\n    print(f\"TickerResearcher(no key) -> ValueError: {e}\")\nfinally:\n    if _saved:\n        _os.environ[\"TAVILY_API_KEY\"] = _saved",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}