{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": "# `webai.tools` — User Guide\n\nUnified web search interface over **Tavily** and **OpenAI** web search, with normalized `SearchResult` output and optional LangChain `Document` conversion.\n\n```\nwebai/tools.py\n│\n├── SearchProvider (Enum)\n│   ├── TAVILY                       Tavily Search API\n│   └── OPENAI                       OpenAI native web search\n│\n├── SearchResult (dataclass)\n│   ├── title: str\n│   ├── content: str\n│   ├── source: str\n│   └── raw_data: dict\n│\n└── WebSearcher\n    ├── __init__(provider, tavily_api_key, openai_api_key,\n    │            max_results, include_raw_content, debug)\n    │\n    ├── search_tavily(query, topic)   → list[SearchResult]   direct Tavily call\n    ├── search_openai(query)          → list[SearchResult]   direct OpenAI call\n    ├── search(query, provider,       → list[SearchResult]   unified + fallback\n    │         topic, fallback)\n    │\n    ├── format_results(results)       → str    numbered list, title+source+content\n    ├── format_minimal(results)       → str    title+content, no source\n    ├── format_content_only(results)  → str    content with dividers\n    ├── get_content_only(results)     → str    joined plain text\n    ├── get_content_list(results)     → list[str]\n    ├── get_first_content(results)    → str | None\n    └── to_documents(results)         → list[Document]\n```\n\n| Section | Needs API keys |\n|---|---|\n| 1 — Setup | No |\n| 2 — Data types | No |\n| 3 — Initialization | No |\n| 4 — Provider-specific search | Yes (`TAVILY_API_KEY` / `OPENAI_API_KEY`) |\n| 5 — Unified `search()` | Yes |\n| 6 — Formatting methods | **No** (uses mock results) |\n| 7 — End-to-end pattern | Yes |\n| 8 — Error handling reference | Partial |\n\n## Sections\n1. [Setup](#1-setup)\n2. [Data types](#2-data-types)\n3. [Initialization](#3-initialization)\n4. [Provider-specific search](#4-provider-specific-search)\n5. [Unified search() with fallback](#5-unified-search-with-fallback)\n6. [Formatting methods](#6-formatting-methods)\n7. [End-to-end pattern](#7-end-to-end-pattern)\n8. [Error handling reference](#8-error-handling-reference)"
  },
  {
   "cell_type": "markdown",
   "id": "qglq2bxna7",
   "source": "## 1 — Setup <a id=\"1-setup\"></a>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "x0md7tfc4g8",
   "source": "import logging\nimport os\n\nfrom dotenv import load_dotenv\n\nfrom webai.tools import SearchProvider, SearchResult, WebSearcher\n\nload_dotenv()\n\nlogging.basicConfig(\n    level=logging.WARNING,  # flip to DEBUG to see full internal trace\n    format=\"%(asctime)s [%(levelname)s] %(name)s — %(message)s\",\n    force=True,\n)\n\n_HAS_TAVILY = bool(os.environ.get(\"TAVILY_API_KEY\"))\n_HAS_OPENAI = bool(os.environ.get(\"OPENAI_API_KEY\"))\n\nprint(f\"TAVILY_API_KEY : {'set' if _HAS_TAVILY else 'MISSING'}\")\nprint(f\"OPENAI_API_KEY : {'set' if _HAS_OPENAI else 'MISSING'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "w7rj05w4mo",
   "source": "## 2 — Data types <a id=\"2-data-types\"></a>\n\nThese two types are the lingua franca of the module. Everything that goes into a search is a `SearchProvider`; everything that comes out is a `SearchResult`.\n\n### 2a — `SearchProvider`\n\nAn `Enum` that selects the search backend. Pass it to `WebSearcher(provider=...)` or to a specific `search()` call as an override.\n\n| Member | Value | Behaviour |\n|---|---|---|\n| `SearchProvider.TAVILY` | `\"tavily\"` | Returns N structured results with real URLs |\n| `SearchProvider.OPENAI` | `\"openai\"` | Returns 1 synthesized prose answer |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "u4poztmggq",
   "source": "# Enumerate members — no API key needed\nfor member in SearchProvider:\n    print(f\"SearchProvider.{member.name:8s}  value={member.value!r}\")\n\n# Access by value (useful when deserialising stored config)\nprovider_from_string = SearchProvider(\"tavily\")\nprint(f\"\\nSearchProvider('tavily') -> {provider_from_string}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cglghhdfe0i",
   "source": "### 2b — `SearchResult`\n\nA frozen-ish `dataclass` that normalises the raw provider response into a consistent shape.\n\n| Field | Type | Notes |\n|---|---|---|\n| `title` | `str` | Real page title (Tavily) or `\"Web search: <query>\"` (OpenAI) |\n| `content` | `str` | Page snippet or full synthesized prose |\n| `source` | `str` | Source URL; may be `\"\"` for OpenAI results |\n| `raw_data` | `dict` | Original provider response dict for advanced use |\n\nYou can construct `SearchResult` objects directly — useful for testing formatting methods without making live API calls.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "klp0vkxy7rh",
   "source": "# Construct results manually — no API key needed\nr = SearchResult(\n    title=\"Nvidia Q4 2025 Earnings Beat\",\n    content=\"Nvidia reported Q4 revenue of $39.3B, up 78% year-over-year, driven by data-center GPU demand.\",\n    source=\"https://www.reuters.com/technology/nvidia-earnings-2025\",\n    raw_data={\"score\": 0.99, \"url\": \"https://www.reuters.com/technology/nvidia-earnings-2025\"},\n)\n\nprint(f\"title   : {r.title}\")\nprint(f\"content : {r.content}\")\nprint(f\"source  : {r.source}\")\nprint(f\"raw_data: {r.raw_data}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "j0sholda7sq",
   "source": "## 3 — Initialization <a id=\"3-initialization\"></a>\n\n`WebSearcher.__init__` initializes both provider clients eagerly and **never raises** — missing keys cause the respective provider to be silently skipped. The first call to a missing provider raises `ValueError` at search time.\n\n### Constructor parameters\n\n| Parameter | Default | Effect |\n|---|---|---|\n| `provider` | `SearchProvider.OPENAI` | Default provider for `search()` calls |\n| `tavily_api_key` | `$TAVILY_API_KEY` | Falls back to env var |\n| `openai_api_key` | `$OPENAI_API_KEY` | Falls back to env var |\n| `max_results` | `5` | Max Tavily results; **ignored** by OpenAI |\n| `include_raw_content` | `False` | Full page text from Tavily; **ignored** by OpenAI |\n| `debug` | `False` | Sets `webai.tools` logger to `DEBUG` (backwards-compat shortcut) |\n\n> **Both keys in `.env`:** Even if you only use one provider, the other client initializes silently when its key is present. Only the key you need is strictly required.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "utc0yiepr2f",
   "source": "# Tavily-only searcher — OpenAI key is optional here\ntavily_searcher = WebSearcher(\n    provider=SearchProvider.TAVILY,\n    max_results=5,\n    include_raw_content=False,\n)\nprint(f\"provider             : {tavily_searcher.provider}\")\nprint(f\"max_results          : {tavily_searcher.max_results}\")\nprint(f\"include_raw_content  : {tavily_searcher.include_raw_content}\")\nprint(f\"tavily_tool ready    : {tavily_searcher.tavily_tool is not None}\")\nprint(f\"openai ready         : {tavily_searcher.llm is not None}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "hcqlra482fb",
   "source": "# Full searcher — both providers initialized if both keys are present\nfull_searcher = WebSearcher(\n    provider=SearchProvider.TAVILY,  # default for .search() calls\n    max_results=3,\n)\nprint(f\"tavily_tool ready : {full_searcher.tavily_tool is not None}\")\nprint(f\"openai ready      : {full_searcher.llm is not None}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "o9ee3312zz9",
   "source": "## 4 — Provider-specific search <a id=\"4-provider-specific-search\"></a>\n\nCall `search_tavily` or `search_openai` directly when you need explicit control over the provider and don't want the fallback logic of `search()`.\n\n### 4a — `search_tavily(query, topic)`\n\nReturns up to `max_results` structured `SearchResult` objects with real titles, URLs, and page snippets.\n\n| `topic` value | Best for |\n|---|---|\n| `\"general\"` | Broad web search (default) |\n| `\"news\"` | Recent news articles |\n| `\"finance\"` | Financial data, earnings, market news |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0h1qyhx1fydo",
   "source": "if not _HAS_TAVILY:\n    print(\"Skipping — requires TAVILY_API_KEY.\")\nelse:\n    results = tavily_searcher.search_tavily(\n        \"NVIDIA earnings 2025\", topic=\"finance\"\n    )\n\n    print(f\"Results returned : {len(results)}\")\n    print()\n    for i, r in enumerate(results, 1):\n        print(f\"[{i}] {r.title}\")\n        print(f\"    source  : {r.source}\")\n        print(f\"    content : {r.content[:120]}...\")\n        print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "v7xr4sc70o",
   "source": "### 4b — `search_openai(query)`\n\nReturns **one** `SearchResult` whose `content` is a synthesized prose answer from OpenAI's built-in web search tool. `max_results`, `include_raw_content`, and `topic` have no effect here.\n\nThe `source` field may be empty if OpenAI's response did not include URL citations in `AIMessage.additional_kwargs[\"annotations\"]`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4guvd66q9q6",
   "source": "if not _HAS_OPENAI:\n    print(\"Skipping — requires OPENAI_API_KEY.\")\nelse:\n    openai_searcher = WebSearcher(provider=SearchProvider.OPENAI)\n    results_openai = openai_searcher.search_openai(\"NVIDIA earnings 2025\")\n\n    print(f\"Results returned : {len(results_openai)}  (always 1 for OpenAI)\")\n    r = results_openai[0]\n    print(f\"title   : {r.title}\")\n    print(f\"source  : {r.source!r}  (may be empty string)\")\n    print(f\"content : {r.content[:300]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0yv9b7vlfble",
   "source": "## 5 — Unified `search()` with fallback <a id=\"5-unified-search-with-fallback\"></a>\n\n`search()` is the main entry point for most use-cases. It dispatches to the configured provider and retries with the other one when `fallback=True` (the default).\n\n### Parameters\n\n| Parameter | Default | Notes |\n|---|---|---|\n| `query` | *(required)* | Search query string |\n| `provider` | instance default | Per-call override; does not change `self.provider` |\n| `topic` | `\"general\"` | Tavily topic; emits `UserWarning` if passed to OpenAI |\n| `fallback` | `True` | Retry with the other provider on failure |\n\n### Fallback logic\n\n```\nsearch(query, provider=TAVILY, fallback=True)\n    └─ try search_tavily(query, topic)\n           OK  -> return results\n           ERR -> try search_openai(query)\n                      OK  -> return results\n                      ERR -> raise RuntimeError(\"Both providers failed...\")\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6jtqegfkv9q",
   "source": "# Basic search() call using the instance default provider (Tavily)\nif not _HAS_TAVILY:\n    print(\"Skipping — requires TAVILY_API_KEY.\")\nelse:\n    results = full_searcher.search(\"AI chip market trends 2025\")\n    print(f\"Provider used    : {full_searcher.provider.value}\")\n    print(f\"Results returned : {len(results)}\")\n    for i, r in enumerate(results, 1):\n        print(f\"  [{i}] {r.title[:80]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "wr0gtbca5wh",
   "source": "# Per-call provider override — force OpenAI for this one query\n# even though the instance default is Tavily\nif not _HAS_OPENAI:\n    print(\"Skipping — requires OPENAI_API_KEY.\")\nelse:\n    import warnings\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")  # suppress topic= warning for demo\n        results_oa = full_searcher.search(\n            \"AI chip market trends 2025\",\n            provider=SearchProvider.OPENAI,\n        )\n    print(f\"Results returned : {len(results_oa)}  (always 1 for OpenAI)\")\n    print(f\"Content preview  : {results_oa[0].content[:300]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "j97z3ehwqb8",
   "source": "## 6 — Formatting methods <a id=\"6-formatting-methods\"></a>\n\nAll seven formatters are **pure functions** over `list[SearchResult]` — no network calls. This section uses hand-crafted mock results so it runs without any API keys.\n\n| Method | Returns | Includes source | Best for |\n|---|---|---|---|\n| `format_results` | `str` | Yes | Human-readable output, debugging |\n| `format_minimal` | `str` | No | Clean display without attribution |\n| `format_content_only` | `str` | No | Divider-separated snippets |\n| `get_content_only` | `str` | No | Newline-joined string for LLM context |\n| `get_content_list` | `list[str]` | No | Programmatic content access |\n| `get_first_content` | `str\\|None` | No | Quick \"top result\" extraction |\n| `to_documents` | `list[Document]` | In metadata | LangChain pipeline integration |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "9zt8113hij",
   "source": "# Shared mock results used in all formatting cells below — no API key needed\nMOCK_RESULTS = [\n    SearchResult(\n        title=\"NVIDIA Q4 2025 Earnings Beat Expectations\",\n        content=\"Nvidia reported Q4 revenue of $39.3B, up 78% YoY, led by data-center GPU demand from hyperscalers.\",\n        source=\"https://www.reuters.com/technology/nvidia-q4-2025\",\n        raw_data={\"score\": 0.99},\n    ),\n    SearchResult(\n        title=\"AMD Challenges Nvidia in AI Chip Race\",\n        content=\"AMD's MI300X GPU is gaining traction with cloud providers seeking alternatives to Nvidia's H100.\",\n        source=\"https://www.wsj.com/technology/amd-mi300x-ai-chips\",\n        raw_data={\"score\": 0.97},\n    ),\n    SearchResult(\n        title=\"Global Semiconductor Outlook 2025\",\n        content=\"Analysts forecast 12% global semiconductor revenue growth in 2025, driven by AI training hardware.\",\n        source=\"https://www.ft.com/content/semiconductor-outlook-2025\",\n        raw_data={\"score\": 0.95},\n    ),\n]\n\n# Shared formatter instance — init with no keys (only used for formatting, not search)\n_fmt = WebSearcher.__new__(WebSearcher)  # bypass __init__ entirely\nprint(f\"Mock results ready: {len(MOCK_RESULTS)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "tjsmte136to",
   "source": "# format_results — numbered list with title, source URL, and content\nprint(\"=== format_results ===\")\nprint(_fmt.format_results(MOCK_RESULTS))\n\n# Empty-list guard\nprint(\"--- empty list ---\")\nprint(_fmt.format_results([]))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "goadrpj40jn",
   "source": "# format_minimal — title + content, no source URL\nprint(\"=== format_minimal ===\")\nprint(_fmt.format_minimal(MOCK_RESULTS))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "hc5pvi3762s",
   "source": "# format_content_only — content blocks separated by numbered dividers\nprint(\"=== format_content_only ===\")\nprint(_fmt.format_content_only(MOCK_RESULTS))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "udrb023dhjj",
   "source": "# get_content_only — single string, newline-joined; ideal as LLM context input\njoined = _fmt.get_content_only(MOCK_RESULTS)\nprint(\"=== get_content_only ===\")\nprint(joined)\n\n# get_content_list — list[str]; one string per result for programmatic access\ncontent_list = _fmt.get_content_list(MOCK_RESULTS)\nprint(f\"\\n=== get_content_list ({len(content_list)} items) ===\")\nfor i, c in enumerate(content_list, 1):\n    print(f\"  [{i}] {c[:60]}...\")\n\n# get_first_content — quick top-result extraction\nfirst = _fmt.get_first_content(MOCK_RESULTS)\nprint(f\"\\n=== get_first_content ===\\n{first}\")\n\n# edge case: empty list returns None\nprint(f\"\\nget_first_content([]) -> {_fmt.get_first_content([])!r}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "whgs9dbk1ji",
   "source": "# to_documents — LangChain Document objects for RAG/retrieval pipelines\ndocs = _fmt.to_documents(MOCK_RESULTS)\n\nprint(f\"=== to_documents ({len(docs)} docs) ===\")\nfor i, doc in enumerate(docs, 1):\n    print(f\"\\n[{i}]\")\n    print(f\"  page_content : {doc.page_content[:80]}...\")\n    print(f\"  metadata.title  : {doc.metadata['title']}\")\n    print(f\"  metadata.source : {doc.metadata['source']}\")\n    print(f\"  metadata keys   : {list(doc.metadata.keys())}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "qwirt5zt8wn",
   "source": "## 7 — End-to-end pattern <a id=\"7-end-to-end-pattern\"></a>\n\nA realistic pipeline: search with Tavily, fall back to OpenAI if needed, then feed the content into an LLM chain as context. The helper is self-contained and uses the `full_searcher` built in section 3.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "86etqjftm7x",
   "source": "def search_and_summarize(\n    searcher: WebSearcher,\n    query: str,\n    topic: str = \"general\",\n    max_chars: int = 2000,\n) -> dict:\n    \"\"\"\n    Search with Tavily (finance topic), build a context string from the\n    top results, and return a structured dict ready to pass to an LLM.\n\n    Args:\n        searcher:  Initialized WebSearcher instance.\n        query:     Search query.\n        topic:     Tavily topic ('general', 'news', 'finance').\n        max_chars: Truncate total context to this many characters.\n\n    Returns:\n        dict with keys 'query', 'n_results', 'sources', 'context'.\n    \"\"\"\n    results = searcher.search(query, topic=topic, fallback=True)\n    context = searcher.get_content_only(results)[:max_chars]\n    sources = [r.source for r in results if r.source]\n    return {\n        \"query\":     query,\n        \"n_results\": len(results),\n        \"sources\":   sources,\n        \"context\":   context,\n    }\n\n\nif not _HAS_TAVILY:\n    print(\"Skipping — requires TAVILY_API_KEY.\")\nelse:\n    payload = search_and_summarize(\n        full_searcher,\n        \"semiconductor sector outlook 2025\",\n        topic=\"finance\",\n    )\n\n    print(f\"query      : {payload['query']}\")\n    print(f\"n_results  : {payload['n_results']}\")\n    print(f\"sources    : {len(payload['sources'])} URLs\")\n    for url in payload[\"sources\"]:\n        print(f\"  {url}\")\n    print(f\"\\ncontext ({len(payload['context'])} chars):\")\n    print(payload[\"context\"][:500], \"...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "10s3g74vuqzd",
   "source": "## 8 — Error handling reference <a id=\"8-error-handling-reference\"></a>\n\n| Method | Condition | Exception |\n|---|---|---|\n| `search_tavily` | Tavily not initialized (missing key) | `ValueError` |\n| `search_tavily` | Tavily API call fails | `RuntimeError` |\n| `search_openai` | OpenAI not initialized (missing key) | `ValueError` |\n| `search_openai` | OpenAI API call fails | `RuntimeError` |\n| `search` | Primary fails + `fallback=False` | re-raises primary exception |\n| `search` | Both providers fail | `RuntimeError(\"Both providers failed...\")` |\n\n> **`__init__` never raises.** Missing keys are silently ignored at construction time; errors surface at search time.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8rkyzo30ssm",
   "source": "# ValueError: search_tavily on a searcher with no Tavily key\n# (Construct a searcher without any keys — __init__ won't raise)\nimport os as _os\n_saved_tv = _os.environ.pop(\"TAVILY_API_KEY\", None)\n_saved_oa = _os.environ.pop(\"OPENAI_API_KEY\", None)\n\nno_key_searcher = WebSearcher()  # no keys -> both tools are None\n\ntry:\n    no_key_searcher.search_tavily(\"test\")\nexcept ValueError as e:\n    print(f\"search_tavily (no key) -> ValueError: {e}\")\n\ntry:\n    no_key_searcher.search_openai(\"test\")\nexcept ValueError as e:\n    print(f\"search_openai (no key) -> ValueError: {e}\")\n\n# Restore keys\nif _saved_tv:\n    _os.environ[\"TAVILY_API_KEY\"] = _saved_tv\nif _saved_oa:\n    _os.environ[\"OPENAI_API_KEY\"] = _saved_oa\nprint(\"Keys restored.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "equp2wdbpad",
   "source": "# fallback=False re-raises the primary error immediately\n# Demonstrated with a no-key searcher (no live call needed)\n_saved_tv = _os.environ.pop(\"TAVILY_API_KEY\", None)\n_saved_oa = _os.environ.pop(\"OPENAI_API_KEY\", None)\n\nno_key_searcher2 = WebSearcher(provider=SearchProvider.TAVILY)\n\ntry:\n    no_key_searcher2.search(\"test query\", fallback=False)\nexcept (ValueError, RuntimeError) as e:\n    print(f\"search(fallback=False) -> {type(e).__name__}: {e}\")\n\nif _saved_tv:\n    _os.environ[\"TAVILY_API_KEY\"] = _saved_tv\nif _saved_oa:\n    _os.environ[\"OPENAI_API_KEY\"] = _saved_oa\nprint(\"Keys restored.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}